{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0ec1d28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Libraries for data preprocessing\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b390aeca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment                                            content\n",
       "0       empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2     sadness                Funeral ceremony...gloomy friday...\n",
       "3  enthusiasm               wants to hang out with friends SOON!\n",
       "4     neutral  @dannycastillo We want to trade with someone w..."
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/campusx-official/jupyter-masterclass/main/tweet_emotions.csv').drop(columns=['tweet_id'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5f8ff458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "\n",
    "# Define text preprocessing functions\n",
    "def lemmatization(text):\n",
    "    \"\"\"Lemmatize the text.\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = text.split()\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    \"\"\"Remove stop words from the text.\"\"\"\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    text = [word for word in str(text).split() if word not in stop_words]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def removing_numbers(text):\n",
    "    \"\"\"Remove numbers from the text.\"\"\"\n",
    "    text = ''.join([char for char in text if not char.isdigit()])\n",
    "    return text\n",
    "\n",
    "def lower_case(text):\n",
    "    \"\"\"Convert text to lower case.\"\"\"\n",
    "    text = text.split()\n",
    "    text = [word.lower() for word in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def removing_punctuations(text):\n",
    "    \"\"\"Remove punctuations from the text.\"\"\"\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
    "    text = text.replace('؛', \"\")\n",
    "    text = re.sub('\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def removing_urls(text):\n",
    "    \"\"\"Remove URLs from the text.\"\"\"\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "def normalize_text(df):\n",
    "    \"\"\"Normalize the text data.\"\"\"\n",
    "    try:\n",
    "        df['content'] = df['content'].apply(lower_case)\n",
    "        df['content'] = df['content'].apply(remove_stop_words)\n",
    "        df['content'] = df['content'].apply(removing_numbers)\n",
    "        df['content'] = df['content'].apply(removing_punctuations)\n",
    "        df['content'] = df['content'].apply(removing_urls)\n",
    "        df['content'] = df['content'].apply(lemmatization)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f'Error during text normalization: {e}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "78520f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = normalize_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "42439308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18401</th>\n",
       "      <td>worry</td>\n",
       "      <td>good night fellow twitterati back work tomorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23114</th>\n",
       "      <td>happiness</td>\n",
       "      <td>need yummy breakfast shift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5890</th>\n",
       "      <td>hate</td>\n",
       "      <td>waste way much paper office nothing worthy alm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28476</th>\n",
       "      <td>relief</td>\n",
       "      <td>crumcake that s relief feel better knowing her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31435</th>\n",
       "      <td>worry</td>\n",
       "      <td>need follower</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            content\n",
       "18401      worry    good night fellow twitterati back work tomorrow\n",
       "23114  happiness                         need yummy breakfast shift\n",
       "5890        hate  waste way much paper office nothing worthy alm...\n",
       "28476     relief  crumcake that s relief feel better knowing her...\n",
       "31435      worry                                      need follower"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1a0a77ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df['sentiment'].isin(['sadness', 'happiness'])\n",
    "df = df[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cea56ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saeed\\AppData\\Local\\Temp\\ipykernel_51120\\2609172714.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['sentiment'] = df['sentiment'].replace({'happiness':1, 'sadness':0})\n"
     ]
    }
   ],
   "source": [
    "df['sentiment'] = df['sentiment'].replace({'happiness':1, 'sadness':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4326c056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>layin n bed headache ughhhh waitin call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>funeral ceremony gloomy friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>sleep im not thinking old friend want married ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>charviray charlene love miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>kelcouch sorry least friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39986</th>\n",
       "      <td>1</td>\n",
       "      <td>going watch boy striped pj s hope cry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39987</th>\n",
       "      <td>1</td>\n",
       "      <td>gave bike thorough wash degrease grease it thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39988</th>\n",
       "      <td>1</td>\n",
       "      <td>amazing time last night mcfly incredible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39994</th>\n",
       "      <td>1</td>\n",
       "      <td>succesfully following tayla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>1</td>\n",
       "      <td>niariley wassup beautiful follow me peep new h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10374 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            content\n",
       "1              0            layin n bed headache ughhhh waitin call\n",
       "2              0                     funeral ceremony gloomy friday\n",
       "6              0  sleep im not thinking old friend want married ...\n",
       "8              0                       charviray charlene love miss\n",
       "9              0                        kelcouch sorry least friday\n",
       "...          ...                                                ...\n",
       "39986          1              going watch boy striped pj s hope cry\n",
       "39987          1  gave bike thorough wash degrease grease it thi...\n",
       "39988          1           amazing time last night mcfly incredible\n",
       "39994          1                        succesfully following tayla\n",
       "39998          1  niariley wassup beautiful follow me peep new h...\n",
       "\n",
       "[10374 rows x 2 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "61f656f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment  content                                                                       \n",
       "1          happy mother s day                                                                8\n",
       "           happy star war day                                                                8\n",
       "0          headache                                                                          5\n",
       "1          good morning everyone                                                             5\n",
       "           happy mother day                                                                  5\n",
       "                                                                                            ..\n",
       "           yum mother s day lunch food business burnside delicious gorgeous day              1\n",
       "           yum whole box cooky                                                               1\n",
       "           yummy taco jack box                                                               1\n",
       "           yummy yum cha mother s day mum dad arcel egg pant yuuuuuum http twitpic com wx    1\n",
       "0          aaaaahhhh friday but funeral                                                      1\n",
       "Name: count, Length: 10296, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e0d4ea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features = 1000)\n",
    "x = vectorizer.fit_transform(df['content'])\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1feff9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8e6a95a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as adnansaeed11\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as adnansaeed11\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"adnansaeed11/19-SESSION\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"adnansaeed11/19-SESSION\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository adnansaeed11/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>-SESSION initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository adnansaeed11/\u001b[1;36m19\u001b[0m-SESSION initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/06 15:45:46 INFO mlflow.tracking.fluent: Experiment with name 'Logistic Regression Baseline Model' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/14a6697035714742a61674110f5ad26b', creation_time=1751798748630, experiment_id='1', last_update_time=1751798748630, lifecycle_stage='active', name='Logistic Regression Baseline Model', tags={}>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dagshub\n",
    "mlflow.set_tracking_uri('https://dagshub.com/adnansaeed11/19-SESSION.mlflow')\n",
    "dagshub.init(repo_owner='adnansaeed11', repo_name='19-SESSION', mlflow=True)\n",
    "\n",
    "mlflow.set_experiment('Logistic Regression Baseline Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "13e4e05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.776867469879518\n",
      "Precision: 0.7690058479532164\n",
      "Recall: 0.7773399014778325\n",
      "F1 Score: 0.7731504164625184\n",
      "🏃 View run beautiful-panda-606 at: https://dagshub.com/adnansaeed11/19-SESSION.mlflow/#/experiments/1/runs/d663c65ad4a14dcca2741c2c0b9a6a1f\n",
      "🧪 View experiment at: https://dagshub.com/adnansaeed11/19-SESSION.mlflow/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump\n",
    "import os\n",
    "\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Log preprocessing params\n",
    "    mlflow.log_param(\"vectorizer\", \"Bag of Words\")\n",
    "    mlflow.log_param(\"num_features\", 1000)\n",
    "    mlflow.log_param(\"test_size\", 0.2)\n",
    "\n",
    "    # Train model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Log model parameters\n",
    "    mlflow.log_param(\"model\", \"Logistic Regression\")\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = model.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "    # Save and log model manually\n",
    "    model_path = \"model.joblib\"\n",
    "    dump(model, model_path)\n",
    "    mlflow.log_artifact(model_path)\n",
    "\n",
    "    # Save and log notebook\n",
    "    notebook_path = \"exp1.ipynb\"\n",
    "    os.system(f\"jupyter nbconvert --to notebook --execute --inplace {notebook_path}\")\n",
    "    mlflow.log_artifact(notebook_path)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce92907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
